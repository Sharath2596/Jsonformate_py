import os
import json
import pandas as pd
from pathlib import Path
from pyxlsb import open_workbook as open_xlsb


def infer_column_type(column_name):
    lower = column_name.lower()
    if "id" in lower or "no" in lower:
        return "integer"
    else:
        return "string"


def extract_schema_and_csv(file_path, output_dir):
    ext = file_path.suffix.lower()
    file_name = file_path.stem
    output_path = output_dir / file_name
    output_path.mkdir(parents=True, exist_ok=True)

    try:
        if ext == ".csv":
            df = pd.read_csv(file_path)
        elif ext == ".xlsb":
            with open_xlsb(file_path) as wb:
                sheet = wb.get_sheet(1)
                data = [[item.v for item in row] for row in sheet.rows()]
                df = pd.DataFrame(data[1:], columns=data[0])
        elif ext in [".xls", ".xlsx"]:
            df = pd.read_excel(file_path, engine="openpyxl")
        else:
            print(f"Skipping unsupported file: {file_path.name}")
            return None, None
    except Exception as e:
        print(f"Error processing {file_path.name}: {e}")
        return None, None

    schema = []
    for idx, col in enumerate(df.columns, start=1):
        schema.append(
            {
                "column_name": col,
                "data_type": infer_column_type(col),
                "column_position": idx,
            }
        )

    df.to_csv(output_path / "part-0000.csv", index=False, header=False)
    return file_name, schema


def preprocess_all_files(input_dir, output_dir):
    input_path = Path(input_dir)
    output_path = Path(output_dir)

    supported_files = (
        list(input_path.glob("*.csv"))
        + list(input_path.glob("*.xls"))
        + list(input_path.glob("*.xlsx"))
        + list(input_path.glob("*.xlsb"))
    )

    if not supported_files:
        print("No supported files found.")
        return

    all_schemas = {}

    for file in supported_files:
        print(f"Processing {file.name}...")
        name, schema = extract_schema_and_csv(file, output_path)
        if name and schema:
            all_schemas[name] = schema

    json_path = output_path / "schemas.json"
    with open(json_path, "w") as f:
        json.dump(all_schemas, f, indent=2)

    print("Preprocessing completed.")


# Define test directories
input_test_dir = "/mnt/data/test_input"
output_test_dir = "/mnt/data/test_output"

# Create directories for test
os.makedirs(input_test_dir, exist_ok=True)
os.makedirs(output_test_dir, exist_ok=True)

# Run the function on test directories
preprocess_all_files(input_test_dir, output_test_dir)

# List the files in output directory for verification
os.listdir(output_test_dir)

preprocess_all_files(
    "C:/Users/sharu/Downloads/Work/Input", "C:/Users/sharu/Downloads/Work/Output"
)

